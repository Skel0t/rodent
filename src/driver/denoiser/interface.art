#[import(cc = "C")] fn mkl_blas_mm_mult(_m: i32, _n: i32, _k: i32, _a: &[f32], _lda: i32, _b: &[f32], _ldb: i32, _c: &mut[f32], _ldc: i32) -> ();
#[import(cc = "C")] fn mkl_add_constant(_n: i32, _a: &[f32], _val: f32, _res: &mut[f32]) -> ();
#[import(cc = "C")] fn mkl_add_elemwise(_n: i32, _a: &[f32], _b: &[f32], _c: &mut[f32]) -> ();
#[import(cc = "C")] fn mkl_apply_relu(_n: i32, _a: &[f32], _c: &mut[f32]) -> ();
#[import(cc = "C")] fn cublas_gemm(_d_A: &[f32], _d_B: &[f32], _d_C: &[f32], _a_width: i32, _a_height: i32, _b_width: i32, _device: i32) -> ();

/* Returns necessary memory for the denoising neural network, so that it can be
   allocated in C++. Hard coded constants. */
#[export]
fn @get_necessary_mem(width: i32, height: i32) -> i64 {
    let size_im2col = (width as i64) * (height as i64) * (9 as i64) * (73 /* max(<in channels>/<shrinked_size>) */ as i64);  /* max size for im2col matrix */
    let size_img    = (width as i64) * (height as i64) * (32 /* max(<out channels>/<shrinked_size>) */ as i64); /* max size to save matmul output */
    /* sizes to save cross-connections */
    let size_pool_3 = (width as i64) * (height as i64) * (32 as i64) / (4 * 4 * 4);
    let size_pool_2 = (width as i64) * (height as i64) * (16 as i64) / (4 * 4);
    let size_pool_1 = (width as i64) * (height as i64) * (12 as i64) / (4);

    4 * (size_im2col + size_img + size_pool_1 + size_pool_2 + size_pool_3)
}

/* Interface function to denoise with the given data with the denoising network. */
#[export]
fn @forward_denoise(img_buf: &Buffer, alb_buf: &Buffer, nrm_buf: &Buffer, mem: &Buffer,
                    width: i32, height: i32, out_buf: &Buffer, kernels: &Buffer, biases: &Buffer) -> () {
    let nn = make_denoise_nn(*kernels, *biases, width, height);
    nn.forward(*img_buf, *alb_buf, *nrm_buf, *mem, *out_buf);
}
