enum MemoryFormat {
    CHW, HWC
}

struct Matrix {
    buf      : Buffer,
    offset   : i64,
    channels : i32,
    format   : MemoryFormat,
    rows     : i32,
    cols     : i32
}

struct AccM {
    read  : fn(i32, i32, i32) -> f32,
    write : fn(i32, i32, i32, f32) -> ()
}

fn @make_matrix(buffer: Buffer, offset: i64, format: MemoryFormat, channels: i32, rows: i32, cols: i32) -> Matrix {
    Matrix { buf = buffer, offset = offset, format = format, channels = channels, rows = rows, cols = cols }
}

/* Returns a Matrix accessor, no matter the memory layout (CHW or HWC) */
fn @get_mat_acc(m: Matrix) -> AccM {
    fn @get_mat_acc_hwc(m: Matrix) -> AccM {
        AccM {
            read  = @|row, col, chn|      { bitcast[&   [f32]](m.buf.data)(m.offset + ((row * m.cols + col) * m.channels + chn) as i64) },
            write = @|row, col, chn, val| { bitcast[&mut[f32]](m.buf.data)(m.offset + ((row * m.cols + col) * m.channels + chn) as i64) = val; }
        }
    }

    fn @get_mat_acc_chw(m: Matrix) -> AccM {
        AccM {
            read  = @|row, col, chn|      { bitcast[&   [f32]](m.buf.data)(m.offset + (row * m.cols + col + chn * m.cols * m.rows) as i64) },
            write = @|row, col, chn, val| { bitcast[&mut[f32]](m.buf.data)(m.offset + (row * m.cols + col + chn * m.cols * m.rows) as i64) = val; }
        }
    }

    match m.format {
        MemoryFormat::CHW => get_mat_acc_chw(m),
        MemoryFormat::HWC => get_mat_acc_hwc(m)
    }
}

/* Takes two matrix accessors and the number of channels the first one is accessing.
   Returns a concatenated accessor, accessing the channels of the second accessor
   if the given channel exceeds channel count of the first accessor. */
fn @get_cat_mat_acc(acc1: AccM, acc2: AccM, channels1: i32) -> AccM {
    AccM {
        read  = @|row, col, chn|      { if chn < channels1 { acc1.read(row, col, chn)        } else { acc2.read(row, col, chn - channels1) } },
        write = @|row, col, chn, val| { if chn < channels1 { acc1.write(row, col, chn, val); } else { acc2.write(row, col, chn - channels1, val); } }
    }
}

/* a and b need to have same channel format. */
fn @matmul(a: Matrix, b: Matrix, biases: fn(i32) -> f32, act_fn: fn(f32) -> f32, buf: Buffer, off: i64) -> Matrix {
    let mat = make_matrix(buf, off, MemoryFormat::HWC, 1, a.rows, b.cols);
    let a_acc = get_mat_acc(a);
    let b_acc = get_mat_acc(b);
    let m_acc = get_mat_acc(mat);

    /* Constant variables defining the block size */
    let c_size = 64;
    let i_size = 16;

    /* Needs c_size many elements. Even though it is known at compile-time
       AnyDSL doesn't currently support putting c_size here */
    let mut m : [f32 * 64];

    let c_vec_len = round_down(mat.cols, c_size);
    let i_vec_len = round_down(a.cols, i_size);

    /* Vectorize over mat.cols with c_size vectors */
    for c in range_step(0, c_vec_len, c_size) {
        /* ii loop for ii = 0 */
        for r in range(0, mat.rows) {
            let b = biases(r);
            vectorize(64, @|j| {
                m(j) = b;
                for i in unroll(0, i_size) {
                    m(j) += a_acc.read(r, i, 0) * b_acc.read(i, c + j, 0);
                }
                m_acc.write(r, c + j, 0, m(j));
            });
        }

        /* ii loop for ii > 0 and last multiple of i_size < ii */
        for ii in range_step(i_size, i_vec_len, i_size) {
            for r in range(0, mat.rows) {
                vectorize(64, @|j| {
                    m(j) = m_acc.read(r, c + j, 0);
                    for i_loop in unroll(0, i_size) {
                        let i = i_loop + ii;
                        m(j) += a_acc.read(r, i, 0) * b_acc.read(i, c + j, 0);
                    }
                    m_acc.write(r, c + j, 0, m(j));
                });
            }
        }

        /* ii loop for ii > (last multiple of i_size < ii) */
        for r in range(0, mat.rows) {
            for c_inner in range(c, imin(c + c_size, mat.cols)) {
                m(0) = m_acc.read(r, c_inner, 0);
                for i in range(i_vec_len, a.cols) {
                    m(0) += a_acc.read(r, i, 0) * b_acc.read(i, c_inner, 0);
                }
                m_acc.write(r, c_inner, 0, act_fn(m(0)));
            }
        }
    }

    /* Do the remaining part without vectorization */
    for c in range(c_vec_len, mat.cols) {
        /* ii loop for ii = 0 */
        for r in range(0, mat.rows) {
            m(0) = biases(r);
            for i_loop in unroll(0, i_size) {
                let i = i_loop;
                m(0) += a_acc.read(r, i, 0) * b_acc.read(i, c, 0);
            }
            m_acc.write(r, c, 0, m(0));
        }

        /* ii loop for ii > 0 and last multiple of i_size < ii */
        for ii in range_step(i_size, i_vec_len, i_size) {
            for r in range(0, mat.rows) {
                m(0) = m_acc.read(r, c, 0);
                for i_loop in unroll(0, i_size) {
                    let i = i_loop + ii;
                    m(0) += a_acc.read(r, i, 0) * b_acc.read(i, c, 0);
                }
                m_acc.write(r, c, 0, m(0));
            }
        }

        /* ii loop for ii > (last multiple of i_size < ii) */
        for r in range(0, mat.rows) {
            m(0) = m_acc.read(r, c, 0);
            for i in range(i_vec_len, a.cols) {
                m(0) += a_acc.read(r, i, 0) * b_acc.read(i, c, 0);
            }
            m_acc.write(r, c, 0, act_fn(m(0)));
        }
    }

    mat
}

/* a and b need to have same channel format */
fn @mkl_matmul(a: Matrix, b: Matrix, biases: fn(i32) -> f32, act_fn: fn(f32) -> f32, buf: Buffer, off: i64) {
    let c = make_matrix(buf, off, MemoryFormat::HWC, 1, a.rows, b.cols);
    mkl_blas_mm_mult(/*m*/ a.rows, /*n*/ b.cols, /*k*/ a.cols,
        /*a*/ bitcast[&   [f32]](&(a.buf.data(4 * a.offset))), /*lda*/ a.cols,
        /*b*/ bitcast[&   [f32]](&(b.buf.data(4 * b.offset))), /*ldb*/ b.cols,
        /*c*/ bitcast[&mut[f32]](&(c.buf.data(4 * c.offset))), /*ldc*/ b.cols);

    for acc, v, row, col, chn in iterate_matrix_par(c) {
        acc.write(row, col, chn, act_fn(v + biases(row)));  // 1 channel per row, thus access  row-th bias
    }
    c
}

/* a and b need to have same channel format. */
fn @cublas_matmul(a: Matrix, b: Matrix, device: i32, buf: Buffer, off: i64) {
    let c = make_matrix(buf, off, MemoryFormat::HWC, 1, a.rows, b.cols);

    let d_a = runtime_alloc(runtime_device(1, device), 4 * a.rows as i64 * a.cols as i64 * a.channels as i64);
    let d_b = runtime_alloc(runtime_device(1, device), 4 * b.rows as i64 * b.cols as i64 * b.channels as i64);
    let d_c = runtime_alloc(runtime_device(1, device), 4 * c.rows as i64 * c.cols as i64 * c.channels as i64);

    copy_host_to_dev(bitcast[&   [i8]](&(a.buf.data(4 * a.offset))), d_a, device, 4 * a.rows as i64 * a.cols as i64 * a.channels as i64);
    copy_host_to_dev(bitcast[&   [i8]](&(b.buf.data(4 * b.offset))), d_b, device, 4 * b.rows as i64 * b.cols as i64 * b.channels as i64);

    cublas_gemm(
        /*a*/ bitcast[&   [f32]](d_a),
        /*b*/ bitcast[&   [f32]](d_b),
        /*c*/ bitcast[&mut[f32]](d_c),
        /*lda*/ a.cols, /*ldb*/ a.rows, /*ldc*/ b.cols, device);

    copy_dev_to_host(bitcast[&mut[i8]](&(c.buf.data(4 * c.offset))), d_c, device, 4 * c.rows as i64 * c.cols as i64 * c.channels as i64);
    runtime_release(runtime_device(1, device), d_a);
    runtime_release(runtime_device(1, device), d_b);
    runtime_release(runtime_device(1, device), d_c);
    c
}

fn @copy_host_to_dev(host_memory: &[i8], device_memory: &mut [i8], dev: i32, size: i64) -> () {
    runtime_copy(runtime_device(0, 0), host_memory, 0, runtime_device(1, dev), device_memory, 0, size);
}

fn @copy_dev_to_host(host_memory: &mut [i8], device_memory: &[i8], dev: i32, size: i64) -> () {
    runtime_copy(runtime_device(1, dev), device_memory, 0, runtime_device(0, 0), host_memory, 0, size);
}

/* Matrices a and b need to have the same dimensions. */
fn @add_element_wise(a: Matrix, b: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res = make_matrix(buf, off, a.format, a.channels, a.rows, a.cols);

    let res_acc  = get_mat_acc(res);
    let b_acc = get_mat_acc(b);

    for _acc, v, r, c, chn in iterate_matrix_par(a) {
        res_acc.write(r, c, chn, b_acc.read(r, c, chn) + v);
    }

    res
}

/* Copies the given matrix to the given buffer and offset in HWC format. */
fn @chw_to_hwc(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res = make_matrix(buf, off, MemoryFormat::HWC, img_mat.channels, img_mat.rows, img_mat.cols);

    let img_acc = get_mat_acc(img_mat);

    for res_acc, _v, row, col, chn in iterate_matrix_par(res) {
        res_acc.write(row, col, chn, img_acc.read(row, col, chn));
    }

    res
}
