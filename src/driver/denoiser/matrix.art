enum MemoryFormat {
    CHW, HWC
}

struct Matrix {
    buf      : Buffer,
    offset   : i64,
    channels : i32,
    format   : MemoryFormat,
    rows     : i32,
    cols     : i32
}

struct AccM {
    read  : fn(i32, i32, i32) -> f32,
    write : fn(i32, i32, i32, f32) -> ()
}

fn @make_matrix(buffer: Buffer, offset: i64, format: MemoryFormat, channels: i32, rows: i32, cols: i32) -> Matrix {
    Matrix { buf = buffer, offset = offset, format = format, channels = channels, rows = rows, cols = cols }
}

fn @get_mat_acc(m: Matrix) -> AccM {
    fn @get_mat_acc_hwc(m: Matrix) -> AccM {
        AccM {
            read  = @|row, col, chn|      { bitcast[&   [f32]](m.buf.data)(m.offset + ((row * m.cols + col) * m.channels + chn) as i64) },
            write = @|row, col, chn, val| { bitcast[&mut[f32]](m.buf.data)(m.offset + ((row * m.cols + col) * m.channels + chn) as i64) = val; }
        }
    }

    fn @get_mat_acc_chw(m: Matrix) -> AccM {
        AccM {
            read  = @|row, col, chn|      { bitcast[&   [f32]](m.buf.data)(m.offset + (row * m.cols + col + chn * m.cols * m.rows) as i64) },
            write = @|row, col, chn, val| { bitcast[&mut[f32]](m.buf.data)(m.offset + (row * m.cols + col + chn * m.cols * m.rows) as i64) = val; }
        }
    }

    match m.format {
        MemoryFormat::CHW => get_mat_acc_chw(m),
        MemoryFormat::HWC => get_mat_acc_hwc(m)
    }
}

fn @get_cat_mat_acc(acc1: AccM, acc2: AccM, channels1: i32) -> AccM {
    AccM {
        read  = @|row, col, chn|      { if chn < channels1 { acc1.read(row, col, chn)        } else { acc2.read(row, col, chn - channels1) } },
        write = @|row, col, chn, val| { if chn < channels1 { acc1.write(row, col, chn, val); } else { acc2.write(row, col, chn - channels1, val); } }
    }
}

fn @matmul(a: Matrix, b: Matrix, biases: fn(i32) -> f32, buf: Buffer, off: i64) -> Matrix {
    let mat = make_matrix(buf, off, MemoryFormat::HWC, 1, a.rows, b.cols);
    let a_acc = get_mat_acc(a);
    let b_acc = get_mat_acc(b);
    let m_acc = get_mat_acc(mat);

    let c_size = 64;
    let i_size = 16;

    let mut m : [f32 * 64];

    let c_vec_len = round_down(mat.cols, c_size);

    for c in range_step(0, c_vec_len, c_size) {
        for r in range(0, mat.rows) {
            let b = biases(r);
            vectorize(64, @|j| {
                m(j) = b;
                for i in unroll(0, i_size) {
                    m(j) += a_acc.read(r, i, 0) * b_acc.read(i, c + j, 0);
                }
                m_acc.write(r, c + j, 0, m(j));
            });
        }

        let i_vec_len = round_down(a.cols, i_size);

        for ii in range_step(i_size, i_vec_len, i_size) {
            for r in range(0, mat.rows) {
                vectorize(64, @|j| {
                    m(j) = m_acc.read(r, c + j, 0);
                    for i_loop in unroll(0, i_size) {
                        let i = i_loop + ii;
                        m(j) += a_acc.read(r, i, 0) * b_acc.read(i, c + j, 0);
                    }
                    m_acc.write(r, c + j, 0, m(j));
                });
            }
        }
        for r in range(0, mat.rows) {
            for c_inner in range(c, imin(c + c_size, mat.cols)) {
                m(0) = m_acc.read(r, c_inner, 0);
                for i in range(i_vec_len, a.cols) {
                    m(0) += a_acc.read(r, i, 0) * b_acc.read(i, c_inner, 0);
                }
                m_acc.write(r, c_inner, 0, m(0));
            }
        }
    }
    for c in range(c_vec_len, mat.cols) {

        let i_vec_len = round_down(a.cols, i_size);

        for ii in range_step(i_size, i_vec_len, i_size) {
            for r in range(0, mat.rows) {
                m(0) = m_acc.read(r, c, 0);
                for i_loop in unroll(0, i_size) {
                    let i = i_loop + ii;
                    m(0) += a_acc.read(r, i, 0) * b_acc.read(i, c, 0);
                }
                m_acc.write(r, c, 0, m(0));
            }
        }
        for r in range(0, mat.rows) {
            for c_inner in range(c, imin(c + c_size, mat.cols)) {
                m(0) = m_acc.read(r, c_inner, 0);
                for i in range(i_vec_len, a.cols) {
                    m(0) += a_acc.read(r, i, 0) * b_acc.read(i, c_inner, 0);
                }
                m_acc.write(r, c_inner, 0, m(0));
            }
        }
    }

    mat
}

fn @imin(a: i32, b: i32) -> i32 {
    if a < b { a } else { b }
}

// Need to have same channel format
fn @mkl_matmul(a: Matrix, b: Matrix, biases: fn(i32) -> f32, buf: Buffer, off: i64) {
    let c = make_matrix(buf, off, MemoryFormat::HWC, 1, a.rows, b.cols);
    mkl_blas_mm_mult(/*m*/ a.rows, /*n*/ b.cols, /*k*/ a.cols,
        /*a*/ bitcast[&   [f32]](&(a.buf.data(4 * a.offset))), /*lda*/ a.cols,
        /*b*/ bitcast[&   [f32]](&(b.buf.data(4 * b.offset))), /*ldb*/ b.cols,
        /*c*/ bitcast[&mut[f32]](&(c.buf.data(4 * c.offset))), /*ldc*/ b.cols);

    for acc, v, row, col, chn in iterate_matrix_par(c) {
        acc.write(row, col, chn, v + biases(row));  // 1 channel per row
    }
    c
}

// Need to have same channel format
fn @cublas_matmul(a: Matrix, b: Matrix, device: i32, buf: Buffer, off: i64) {
    let c = make_matrix(buf, off, MemoryFormat::HWC, 1, a.rows, b.cols);

    let d_a = runtime_alloc(runtime_device(1, device), 4 * a.rows as i64 * a.cols as i64 * a.channels as i64);
    let d_b = runtime_alloc(runtime_device(1, device), 4 * b.rows as i64 * b.cols as i64 * b.channels as i64);
    let d_c = runtime_alloc(runtime_device(1, device), 4 * c.rows as i64 * c.cols as i64 * c.channels as i64);

    copy_host_to_dev(bitcast[&   [i8]](&(a.buf.data(4 * a.offset))), d_a, device, 4 * a.rows as i64 * a.cols as i64 * a.channels as i64);
    copy_host_to_dev(bitcast[&   [i8]](&(b.buf.data(4 * b.offset))), d_b, device, 4 * b.rows as i64 * b.cols as i64 * b.channels as i64);

    cublas_gemm(
        /*a*/ bitcast[&   [f32]](d_a),
        /*b*/ bitcast[&   [f32]](d_b),
        /*c*/ bitcast[&mut[f32]](d_c),
        /*lda*/ a.cols, /*ldb*/ a.rows, /*ldc*/ b.cols, device);

    copy_dev_to_host(bitcast[&mut[i8]](&(c.buf.data(4 * c.offset))), d_c, device, 4 * c.rows as i64 * c.cols as i64 * c.channels as i64);
    runtime_release(runtime_device(1, device), d_a);
    runtime_release(runtime_device(1, device), d_b);
    runtime_release(runtime_device(1, device), d_c);
    c
}

fn @copy_host_to_dev(host_memory: &[i8], device_memory: &mut [i8], dev: i32, size: i64) -> () {
    runtime_copy(runtime_device(0, 0), host_memory, 0, runtime_device(1, dev), device_memory, 0, size);
}

fn @copy_dev_to_host(host_memory: &mut [i8], device_memory: &[i8], dev: i32, size: i64) -> () {
    runtime_copy(runtime_device(1, dev), device_memory, 0, runtime_device(0, 0), host_memory, 0, size);
}

fn @add_element_wise(mat1: Matrix, mat2: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res = make_matrix(buf, off, mat1.format, mat1.channels, mat1.rows, mat1.cols);

    let res_acc  = get_mat_acc(res);
    let mat2_acc = get_mat_acc(mat2);
    for _acc, v, r, c, chn in iterate_matrix_par(mat1) {
        res_acc.write(r, c, chn, mat2_acc.read(r, c, chn) + v);
    }
    res
}
