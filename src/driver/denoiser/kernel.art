fn @make_conv_matrix(kernel: Matrix, img_mat: Matrix, buf: Buffer, off: i64) -> Sparse {
    let width    = img_mat.cols;
    let height   = img_mat.rows;
    let channels = img_mat.channels;
    let format   = img_mat.format;

    let ksizeh_r = kernel.rows / 2;
    let ksizeh_c = kernel.cols / 2;

    let mat   = make_sparse(buf, off, width * height, kernel.cols * kernel.rows * kernel.channels);
    let m_acc = get_sparse_acc(mat);
    let k_acc = get_mat_acc(kernel);

    for j in parallel(0, 0, height) {
        for i in range(0, width) {
            let s_row = j * width + i;
            for r in unroll(-ksizeh_r, ksizeh_r+1) {
                for c in unroll(-ksizeh_c, ksizeh_c+1) {
                    let im_row = j + r;
                    let im_col = i + c;

                    let k_row = r + ksizeh_r;
                    let k_col = c + ksizeh_c;

                    let s_col = (k_row * kernel.cols + k_col) * kernel.channels;
                    for channel in unroll(0, channels) {
                        if im_row < 0 || im_col < 0 || im_col >= width || im_row >= height {
                            m_acc.write(s_row, s_col + channel, 0, 0); // padding with 0s s.t. image size at start and end is the same
                            continue()
                        }
                        let mut index : i32;
                        match format {
                            MemoryFormat::HWC => { index = (im_row * width + im_col) * channels + channel; },
                            MemoryFormat::CHW => { index = (im_row * width + im_col) + channel * width * height; }
                        }
                        m_acc.write(s_row, s_col + channel, k_acc.read(k_row, k_col, channel), index);
                    }
                }
            }
        }
    }
    mat
}


fn @convolute(kernel: Matrix, img_mat: Matrix, bias: f32, use_bias: bool, buf: Buffer, off: i64, off_result: i64) -> () {
    let m = reshape_matrix(img_mat, img_mat.rows * img_mat.cols, 1);    // Doesn't really do anything, since m is just used bitcast. But it's necessary to have the right dimensions for multiplication.

    let conv = make_conv_matrix(kernel, img_mat, buf, off);
    let prod = sparse_mult(conv, m, buf, off_result);

    if use_bias {
        for acc, v, r, c, chn in iterate_matrix_par(prod) {
            acc.write(r, c, chn, v + bias);
        }
    }
}

fn @conv2d(out_channels: i32, kernels: fn(i32) -> Matrix, biases: fn(i32) -> f32, img_mat: Matrix, use_bias: bool, buf: Buffer, off: i64) -> Matrix {
    let width  = img_mat.cols;
    let height = img_mat.rows;

    let result_size = width as i64 * height as i64;
    let sparse_size = 2 * (width as i64) * (height as i64) * (kernels(0).cols as i64) * (kernels(0).rows as i64) * (kernels(0).channels as i64);

    for i in range(0, out_channels) {
        let buf_off  = off + i as i64 * result_size + sparse_size;
        convolute(kernels(i), img_mat, biases(i), use_bias, buf, off, buf_off);
    }

    make_matrix(buf, off + sparse_size, MemoryFormat::CHW, out_channels, height, width)
}

fn @max_pool_2(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res_mat = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows / 2, img_mat.cols / 2);
    let img_acc = get_mat_acc(img_mat);

    for r_acc, _v, row, col, chn in iterate_matrix_par(res_mat) {
        let v12 = img_acc.read(2 * row    , 2 * col    , chn);
        let v21 = img_acc.read(2 * row    , 2 * col + 1, chn);
        let v11 = img_acc.read(2 * row + 1, 2 * col    , chn);
        let v22 = img_acc.read(2 * row + 1, 2 * col + 1, chn);

        let val = max(max(v11, v12), max(v21, v22));
        r_acc.write(row, col, chn, val);
    }

    res_mat
}

fn @leaky_relu(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    fn @leaky_relu_x(neg_slope: f32, x: f32) -> f32 {
        if x >= 0.0 {
            x
        } else {
            neg_slope * x
        }
    }

    let res = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows, img_mat.cols);
    let m_acc = get_mat_acc(img_mat);

    for r_acc, _v, r, c, chn in iterate_matrix_par(res) {
        r_acc.write(r, c, chn, leaky_relu_x(0.01, m_acc.read(r, c, chn)));
    }
    res
}

fn @mkl_relu(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows, img_mat.cols);

    let n = img_mat.channels * img_mat.rows * img_mat.cols;

    mkl_apply_relu(n, bitcast[&[f32]](&(img_mat.buf.data(4 * img_mat.offset))), bitcast[&mut[f32]](&(res.buf.data(4 * res.offset))));
    res
}

fn @max(x: f32, y: f32) -> f32 {
    select(x > y, x, y)
}

// Rewrites CHW and to HWC by copying
fn @chw_to_hwc(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res = make_matrix(buf, off, MemoryFormat::HWC, img_mat.channels, img_mat.rows, img_mat.cols);

    let img_acc = get_mat_acc(img_mat);

    for res_acc, _v, row, col, chn in iterate_matrix_par(res) {
        res_acc.write(row, col, chn, img_acc.read(row, col, chn));
    }

    res
}

fn @nearest(img_mat: Matrix, buf: Buffer, off: i64) -> Matrix {
    let res_mat = make_matrix(buf, off, img_mat.format, img_mat.channels, img_mat.rows * 2, img_mat.cols * 2);

    let img_acc = get_mat_acc(img_mat);

    for res_acc, _v, row, col, chn in iterate_matrix_par(res_mat) {
        res_acc.write(row, col, chn, img_acc.read(row / 2, col / 2, chn));
    }

    res_mat
}

fn @conv_with_im2col(ksize: i32, out_channels: i32, flattened_kernels: Matrix, biases: fn(i32) -> f32, img_mat: Matrix, use_bias: bool, buf: Buffer, off: i64, off_res: i64) -> Matrix {
    // insize == outsize if padding == ksize / 2.0 - 1
    let padding    = ksize / 2;
    let out_width  = (img_mat.cols + 2 * padding - ksize) + 1;
    let out_height = (img_mat.rows + 2 * padding - ksize) + 1;

    let im2col_mat = im2col(ksize, out_width, out_height, img_mat.cols, img_mat.rows, img_mat.channels, get_mat_acc(img_mat), padding, buf, off);
    let prod       = mkl_matmul(flattened_kernels, im2col_mat, buf, off_res);

    if use_bias {
        for row in range(0, prod.rows) {
            let offset = 4 * (prod.offset + (row * prod.cols) as i64);
            mkl_add_constant(/*n*/ prod.cols, /*a*/ bitcast[&[f32]](&(prod.buf.data(offset))),
                             /*val*/ biases(row), /*res*/ bitcast[&mut[f32]](&(prod.buf.data(offset))));    // 1 channel per row
        }
    }

    make_matrix(buf, off_res, MemoryFormat::CHW, out_channels, out_height, out_width)
}

// TODO: Change f32's to own type and use sizeof[type]() instead of 4
// Only supporting stride of 1
fn @im2col(ksize: i32, out_width: i32, out_height: i32, in_width: i32, in_height: i32, channels: i32, img_acc: AccM, padding: i32, buf: Buffer, off: i64) -> Matrix {
    let img_s    = (out_width as i64) * (out_height as i64);
    let ksize_sq = (ksize as i64) * (ksize as i64);

    let bc = bitcast[&mut[f32]](buf.data);

    let res_mat = make_matrix(buf, off, MemoryFormat::CHW, 1, channels * ksize_sq as i32, img_s as i32);

    for chn in range(0, channels) {
        for base_col in range(0, img_s as i32) {
            let mut base_row = (chn as i64) * (img_s * ksize_sq);

            let row = base_col / out_width;
            let col = base_col % out_width;

            let p_row = row - padding;
            let p_col = col - padding;

            for y in unroll(0, ksize) {
                for x in unroll(0, ksize) {
                    let h = p_row + y;
                    let w = p_col + x;

                    if h < 0 || w < 0 || h >= in_height || w >= in_width {
                        bc(off + base_row + (base_col as i64)) = 0;
                    } else {
                        bc(off + base_row + (base_col as i64)) = img_acc.read(h, w, chn);
                    }

                    base_row += img_s;
                }
            }

        }
    }

    res_mat
}

fn @cat_conv(ksize: i32, out_channels: i32, in_channels: i32, flattened_kernels: Matrix, biases: fn(i32) -> f32, in_rows: i32, in_cols: i32, img_acc: AccM, use_bias: bool, buf: Buffer, off: i64, off_res: i64) -> Matrix {
    // insize == outsize if padding == ksize / 2.0 - 1
    let padding    = ksize / 2;
    let out_width  = (in_cols + 2 * padding - ksize) + 1;
    let out_height = (in_rows + 2 * padding - ksize) + 1;

    let im2col_mat = im2col(ksize, out_width, out_height, in_cols, in_rows, in_channels, img_acc, padding, buf, off);
    let prod       = mkl_matmul(flattened_kernels, im2col_mat, buf, off_res);

    if use_bias {
        for row in range(0, prod.rows) {
            let offset = 4 * (prod.offset + (row * prod.cols) as i64);
            mkl_add_constant(/*n*/ prod.cols, /*a*/ bitcast[&[f32]](&(prod.buf.data(offset))),
                             /*val*/ biases(row), /*res*/ bitcast[&mut[f32]](&(prod.buf.data(offset))));    // 1 channel per row
        }
    }

    make_matrix(buf, off_res, MemoryFormat::CHW, out_channels, out_height, out_width)
}
